{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Activation, Dropout,BatchNormalization,Input\n",
    "from tensorflow.keras.optimizers import Adam ,RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import  backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from random import random,randrange\n",
    "from operator import itemgetter\n",
    "import timeit\n",
    "\n",
    "from FCMnR import FCMnR_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to https://www.kaggle.com/code/julienjta/flight-price-prediction-98-47-r2-score\n",
    "def preprocessing(df):\n",
    "    #Encode the ordinal variables \"stops\" and \"class\".\n",
    "    df[\"stops\"] = df[\"stops\"].replace({'zero':0,'one':1,'two_or_more':2}).astype(int)\n",
    "    df[\"class\"] = df[\"class\"].replace({'Economy':0,'Business':1}).astype(int)\n",
    "    \n",
    "    #Create the dummy variables for the cities, the times and the airlines.\n",
    "    dummies_variables = [\"airline\",\"source_city\",\"destination_city\",\"departure_time\",\"arrival_time\"]\n",
    "    dummies = pd.get_dummies(df[dummies_variables], drop_first= True)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    \n",
    "    #Create the dummy variables for the cities, the times and the airlines.\n",
    "    df = df.drop([\"flight\",\"airline\",\"source_city\",\"destination_city\",\"departure_time\",\"arrival_time\"],axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv(\"Clean_Dataset.csv\",index_col=0)\n",
    "\n",
    "    df = preprocessing(df)\n",
    "    print(\"There are {} observations for {} predictors.\".format(df.shape[0],df.shape[1]))\n",
    "    df.head()    \n",
    "    X = df.copy()\n",
    "    y = X.pop(\"price\")\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(X,y,random_state = 1,test_size=0.2, shuffle=True)\n",
    "    xtrain,xvalid,ytrain,yvalid = train_test_split(xtrain,ytrain,random_state = 1,test_size=0.2, shuffle=True)\n",
    "    return xtrain,xtest,xvalid,yvalid,ytrain,ytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 300153 observations for 30 predictors.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stops</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>airline_Air_India</th>\n",
       "      <th>airline_GO_FIRST</th>\n",
       "      <th>airline_Indigo</th>\n",
       "      <th>airline_SpiceJet</th>\n",
       "      <th>airline_Vistara</th>\n",
       "      <th>source_city_Chennai</th>\n",
       "      <th>...</th>\n",
       "      <th>departure_time_Early_Morning</th>\n",
       "      <th>departure_time_Evening</th>\n",
       "      <th>departure_time_Late_Night</th>\n",
       "      <th>departure_time_Morning</th>\n",
       "      <th>departure_time_Night</th>\n",
       "      <th>arrival_time_Early_Morning</th>\n",
       "      <th>arrival_time_Evening</th>\n",
       "      <th>arrival_time_Late_Night</th>\n",
       "      <th>arrival_time_Morning</th>\n",
       "      <th>arrival_time_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>47870</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.17</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82547</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.92</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112828</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.92</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.42</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100057</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.42</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stops  class  duration  days_left  airline_Air_India  \\\n",
       "47870       1      0     10.17         26                  0   \n",
       "82547       1      0      4.92         39                  0   \n",
       "112828      1      0     12.92         28                  1   \n",
       "125170      0      0      2.42         36                  0   \n",
       "100057      1      0      4.42         35                  0   \n",
       "\n",
       "        airline_GO_FIRST  airline_Indigo  airline_SpiceJet  airline_Vistara  \\\n",
       "47870                  0               0                 0                1   \n",
       "82547                  0               1                 0                0   \n",
       "112828                 0               0                 0                0   \n",
       "125170                 0               0                 0                1   \n",
       "100057                 0               1                 0                0   \n",
       "\n",
       "        source_city_Chennai  ...  departure_time_Early_Morning  \\\n",
       "47870                     0  ...                             0   \n",
       "82547                     0  ...                             0   \n",
       "112828                    0  ...                             1   \n",
       "125170                    0  ...                             1   \n",
       "100057                    0  ...                             0   \n",
       "\n",
       "        departure_time_Evening  departure_time_Late_Night  \\\n",
       "47870                        0                          0   \n",
       "82547                        0                          0   \n",
       "112828                       0                          0   \n",
       "125170                       0                          0   \n",
       "100057                       1                          0   \n",
       "\n",
       "        departure_time_Morning  departure_time_Night  \\\n",
       "47870                        1                     0   \n",
       "82547                        0                     0   \n",
       "112828                       0                     0   \n",
       "125170                       0                     0   \n",
       "100057                       0                     0   \n",
       "\n",
       "        arrival_time_Early_Morning  arrival_time_Evening  \\\n",
       "47870                            0                     1   \n",
       "82547                            0                     1   \n",
       "112828                           0                     0   \n",
       "125170                           0                     0   \n",
       "100057                           0                     0   \n",
       "\n",
       "        arrival_time_Late_Night  arrival_time_Morning  arrival_time_Night  \n",
       "47870                         0                     0                   0  \n",
       "82547                         0                     0                   0  \n",
       "112828                        0                     0                   1  \n",
       "125170                        0                     1                   0  \n",
       "100057                        0                     0                   1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain,xtest,xvalid,yvalid,ytrain,ytest=load_data()\n",
    "#DATA/TASK INFORMATION:\n",
    "architecture_name=\"fcmnr\"\n",
    "problem_type=\"prediction\"\n",
    "num_features=xtrain.shape[1]\n",
    "input_shape =(xtrain.shape[1])\n",
    "training_and_validation_samples=len(ytrain)+len(yvalid)\n",
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fitness(input_shape,n_layers,activation_function,learning_rate,batch_size,hp_dataset_name,weights_name,max_epochs,patience_epochs):\n",
    "    clear_session()\n",
    "    #CREATE MODEL\n",
    "    model=FCMnR_model(n_layers,input_shape,activation_function,learning_rate)\n",
    "    start_time = timeit.default_timer()\n",
    "    history = model.fit(xtrain,ytrain,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=max_epochs,\n",
    "                        callbacks=[EarlyStopping(patience=patience_epochs)],validation_data=(xvalid,yvalid))\n",
    "    end_time = timeit.default_timer()\n",
    "    \n",
    "    #EVALUATE MODEL\n",
    "    prediction=model.predict(xtest)\n",
    "    mae_test=mean_absolute_error(ytest,prediction)\n",
    "\n",
    "\n",
    "    #SAVE THE WEIGHTS\n",
    "    model.save(weights_name+\".h5\")\n",
    "\n",
    "    #SAVE THE HYPERPARAMS AND THE METRIC\n",
    "    with open(hp_dataset_name, mode='a+') as hp_dataset:\n",
    "        hp_dataset_writer=csv.writer(hp_dataset,delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        hp_dataset_writer.writerow([architecture_name,\n",
    "                                problem_type,\n",
    "                                num_features,\n",
    "                                training_and_validation_samples,\n",
    "                                n_layers,\n",
    "                                input_shape,\n",
    "                                activation_function,\n",
    "                                learning_rate,\n",
    "                                batch_size,\n",
    "                                str(len(history.history['loss'])),\n",
    "                                end_time-start_time,\n",
    "                                mae_test\n",
    "                                ])\n",
    "    return mae_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_gridsearch(population_size,input_shape,n_layers,activation_function,learning_rate,batch_size,hp_dataset_name,max_epochs,patience_epochs):\n",
    "        dict_all_hyperparams=dict(n_layers=n_layers,\n",
    "                                learning_rate=learning_rate,\n",
    "                                activation_function=activation_function,\n",
    "                                batch_size=batch_size,\n",
    "                                )\n",
    "        r_grid_search_population=list(ParameterSampler(dict_all_hyperparams,population_size))\n",
    "        \n",
    "        RGS_evaluated_hparams=[]\n",
    "        with open(\"Logs_RandomGridSearch.csv\", mode='a+') as logs_dataset:\n",
    "                logs_dataset_writer=csv.writer(logs_dataset,delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                logs_dataset_writer.writerow([\"population: \"+str(population_size)])\n",
    "                logs_dataset_writer.writerows(dict(x=r_grid_search_population).values())\n",
    "        print(r_grid_search_population)\n",
    "\n",
    "        \n",
    "        for i in range(len(r_grid_search_population)):\n",
    "                weights_name='{}-{}-{}-{}'.format(r_grid_search_population[i]['n_layers'],r_grid_search_population[i]['activation_function'],r_grid_search_population[i]['learning_rate'],r_grid_search_population[i]['batch_size'])\n",
    "                metric=evaluate_fitness(input_shape,\n",
    "                                r_grid_search_population[i]['n_layers'],\n",
    "                                r_grid_search_population[i]['activation_function'],\n",
    "                                r_grid_search_population[i]['learning_rate'],\n",
    "                                r_grid_search_population[i]['batch_size'],\n",
    "                                hp_dataset_name,\n",
    "                                weights_name,\n",
    "                                max_epochs,\n",
    "                                patience_epochs\n",
    "                                )\n",
    "                \n",
    "                with open(\"Logs_RandomGridSearch.csv\", mode='a+') as logs_dataset:\n",
    "                        logs_dataset_writer=csv.writer(logs_dataset,delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        logs_dataset_writer.writerow([\"i:\"+str(i)+\"Metric:\"+str(metric)])\n",
    "                print(\"i\",i,\"Mae:\",metric)\n",
    "\n",
    "                RGS_evaluated_hparams.insert(len(RGS_evaluated_hparams),{\"hparam\":i,\"metric\":metric})\n",
    "        rgs_top_hparam=sorted(RGS_evaluated_hparams,key=itemgetter('metric'),reverse=True)[0]['hparam']\n",
    "        \n",
    "        with open(\"Logs_RandomGridSearch.csv\", mode='a+') as logs_dataset:\n",
    "                        logs_dataset_writer=csv.writer(logs_dataset,delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        logs_dataset_writer.writerow(\"END\")\n",
    "                        logs_dataset_writer.writerows(sorted(RGS_evaluated_hparams,key=itemgetter('metric'),reverse=True)[0]['metric'],r_grid_search_population[rgs_top_hparam])\n",
    "        \n",
    "        return sorted(RGS_evaluated_hparams,key=itemgetter('metric'),reverse=True)[0]['metric'],r_grid_search_population[rgs_top_hparam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'n_layers': 1, 'learning_rate': 0.0001, 'batch_size': 128, 'activation_function': 'tanh'}, {'n_layers': 1, 'learning_rate': 1e-05, 'batch_size': 64, 'activation_function': 'relu'}, {'n_layers': 3, 'learning_rate': 0.01, 'batch_size': 16, 'activation_function': 'relu'}, {'n_layers': 2, 'learning_rate': 1e-05, 'batch_size': 32, 'activation_function': 'tanh'}, {'n_layers': 3, 'learning_rate': 1e-05, 'batch_size': 16, 'activation_function': 'relu'}]\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 192097 samples, validate on 48025 samples\n",
      "192097/192097 [==============================] - 30s 154us/sample - loss: 20884.1844 - mean_absolute_error: 20884.1953 - val_loss: 20989.8490 - val_mean_absolute_error: 20989.8535\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "i 0 Mae: 20796.95416327683\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 192097 samples, validate on 48025 samples\n",
      "192097/192097 [==============================] - 56s 293us/sample - loss: 20784.4758 - mean_absolute_error: 20784.4883 - val_loss: 20806.3210 - val_mean_absolute_error: 20806.3086\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "i 1 Mae: 20613.38234510436\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 192097 samples, validate on 48025 samples\n",
      " 51456/192097 [=======>......................] - ETA: 3:30 - loss: 20978.6702 - mean_absolute_error: 20978.6465"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-82f0ec9736da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mpopulation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mrandom_gridsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhp_dataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c30c77419e1d>\u001b[0m in \u001b[0;36mrandom_gridsearch\u001b[0;34m(population_size, input_shape, n_layers, activation_function, learning_rate, batch_size, hp_dataset_name, max_epochs, patience_epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m                                 \u001b[0mweights_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                 \u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                                 \u001b[0mpatience_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                                 )\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-91b2fd692ed7>\u001b[0m in \u001b[0;36mevaluate_fitness\u001b[0;34m(input_shape, n_layers, activation_function, learning_rate, batch_size, hp_dataset_name, weights_name, max_epochs, patience_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                         callbacks=[EarlyStopping(patience=patience_epochs)],validation_data=(xvalid,yvalid))\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#HYPERPARAMETERS DEFINITION\n",
    "n_layers = [1,2,3]\n",
    "activation_function=['relu','tanh','sigmoid','elu']\n",
    "learning_rate=[0.01,0.001,0.0001,0.00001]\n",
    "batch_size=[16,32,64,128]\n",
    "max_epochs=1\n",
    "patience_epochs=20\n",
    "\n",
    "#FILES NAME\n",
    "hp_dataset_name=\"hyperparams_with_metric.csv\"\n",
    "\n",
    "#ALGORITHM PARAMS\n",
    "population_size=5\n",
    "\n",
    "random_gridsearch(population_size,input_shape,n_layers,activation_function,learning_rate,batch_size,hp_dataset_name,max_epochs,patience_epochs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "5e66b90ac85f38f39d9ade17082e1282e7794075483f5b8f4b36ae4e18b98d63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
